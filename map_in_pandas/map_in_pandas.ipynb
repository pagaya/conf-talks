{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pagaya-map_in_pandas\n",
    "\n",
    "Easy python wrapper for Spark mapInPandas, applyInPandas\n",
    "\n",
    "[this notebook on github](https://github.com/pagaya/conf-talks/blob/master/map_in_pandas/map_in_pandas.ipynb)\n",
    "\n",
    "## Goal\n",
    "Easily run legacy pandas-based python functions at scale on large amounts of data.\n",
    "\n",
    "## applications\n",
    "* Running legacy transformations, feature extraction etc.\n",
    "* large scale model-evaluation\n",
    "* large scale experiments and parameter tuning.\n",
    "* A-B testing\n",
    "* Concurrent training (e.g. xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/tmp/mappandas/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - map_in_pandas\n",
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------+---------+---------+---------+---------+\n",
      "|amount|application.id|feature_a|feature_b|feature_c|feature_d|feature_e|\n",
      "+------+--------------+---------+---------+---------+---------+---------+\n",
      "|  1000|APP_0000003000|   0.5056|   0.5332|   0.8988|   0.0167|   0.1865|\n",
      "| 77000|APP_0000003001|   0.2841|   0.3322|    0.954|   0.2985|   0.4344|\n",
      "| 23000|APP_0000003002|   0.9934|   0.1634|   0.2316|   0.5968|   0.2253|\n",
      "| 90000|APP_0000003003|   0.5882|   0.8698|   0.7088|   0.2831|   0.7278|\n",
      "| 15000|APP_0000003004|   0.0545|   0.3589|   0.1225|   0.8014|   0.2392|\n",
      "| 96000|APP_0000003005|   0.8458|   0.7208|   0.5997|   0.3011|   0.9883|\n",
      "| 79000|APP_0000003006|   0.2966|   0.8867|   0.9708|   0.4768|   0.0424|\n",
      "| 76000|APP_0000003007|   0.0448|   0.1714|   0.8282|   0.1251|    0.041|\n",
      "| 39000|APP_0000003008|   0.9661|   0.7887|   0.5307|   0.0577|   0.2891|\n",
      "| 17000|APP_0000003009|   0.6397|   0.8368|   0.4307|   0.8176|    0.685|\n",
      "| 96000|APP_0000003010|   0.0657|   0.6655|   0.6241|   0.7948|   0.9734|\n",
      "| 70000|APP_0000003011|   0.7763|   0.7249|   0.5629|   0.4966|   0.3255|\n",
      "| 56000|APP_0000003012|    0.143|   0.7234|   0.4212|   0.1111|   0.1688|\n",
      "|  5000|APP_0000003013|   0.2254|   0.5322|   0.6167|   0.0906|   0.8128|\n",
      "| 74000|APP_0000003014|   0.8215|   0.5169|   0.1601|   0.5618|   0.9019|\n",
      "|  1000|APP_0000003015|   0.4705|   0.2098|   0.8371|   0.8117|   0.8754|\n",
      "| 19000|APP_0000003016|   0.1289|   0.2272|   0.3765|   0.1097|   0.0912|\n",
      "| 37000|APP_0000003017|   0.7934|   0.2458|   0.3023|   0.5972|   0.5391|\n",
      "| 86000|APP_0000003018|   0.2077|   0.1098|   0.5817|   0.1445|   0.8169|\n",
      "| 16000|APP_0000003019|   0.2835|   0.3061|   0.4913|   0.1172|   0.5043|\n",
      "+------+--------------+---------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "applications = spark.read.format(\"json\").load(DATA_PATH)\n",
    "applications.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# legacy code\n",
    "I have many legacy functions that work pandas->pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_preprocessing(pd_df):\n",
    "    pd_df['application.id'] = pd_df['application.id'] + \"/M\"\n",
    "    pd_df['ab'] = pd_df.feature_a + pd_df.feature_b\n",
    "    pd_df['cd'] = pd_df.feature_c * pd_df.feature_d\n",
    "    # remove the 'features_X' columns\n",
    "    return pd_df.drop(columns=[col for col in pd_df.columns if col.startswith(\"feature\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How I want things to work\n",
    "## (pagaya-map_in_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-------------------+--------------------+\n",
      "|amount|  application.id|                 ab|                  cd|\n",
      "+------+----------------+-------------------+--------------------+\n",
      "|  1000|APP_0000003000/M| 1.0388000000000002|0.015009960000000001|\n",
      "| 77000|APP_0000003001/M| 0.6163000000000001|            0.284769|\n",
      "| 23000|APP_0000003002/M|             1.1568|          0.13821888|\n",
      "| 90000|APP_0000003003/M|              1.458|          0.20066128|\n",
      "| 15000|APP_0000003004/M|             0.4134|           0.0981715|\n",
      "| 96000|APP_0000003005/M|             1.5666|          0.18056967|\n",
      "| 79000|APP_0000003006/M|             1.1833|          0.46287744|\n",
      "| 76000|APP_0000003007/M|             0.2162|          0.10360782|\n",
      "| 39000|APP_0000003008/M|             1.7548|          0.03062139|\n",
      "| 17000|APP_0000003009/M| 1.4765000000000001|          0.35214032|\n",
      "| 96000|APP_0000003010/M|             0.7312| 0.49603467999999995|\n",
      "| 70000|APP_0000003011/M| 1.5011999999999999|          0.27953614|\n",
      "| 56000|APP_0000003012/M| 0.8664000000000001|          0.04679532|\n",
      "|  5000|APP_0000003013/M|             0.7576|          0.05587302|\n",
      "| 74000|APP_0000003014/M|             1.3384| 0.08994417999999998|\n",
      "|  1000|APP_0000003015/M| 0.6802999999999999|  0.6794740699999999|\n",
      "| 19000|APP_0000003016/M|0.35609999999999997|          0.04130205|\n",
      "| 37000|APP_0000003017/M|             1.0392| 0.18053355999999998|\n",
      "| 86000|APP_0000003018/M|             0.3175|          0.08405565|\n",
      "| 16000|APP_0000003019/M| 0.5895999999999999|0.057580360000000004|\n",
      "+------+----------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from map_in_pandas import mappandas\n",
    "results = mappandas.map_in_pandas(spark, applications, legacy_preprocessing)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The reality of working with spark.mapInPandas\n",
    "## schema\n",
    "Spark mapInPandas expects me to define a schema. \n",
    "\n",
    "However - I did not write the function - I don't know which fields it returns.\n",
    "\n",
    "I need to run the function on a small chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>application.id</th>\n",
       "      <th>ab</th>\n",
       "      <th>cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>APP_0000003000/M</td>\n",
       "      <td>1.0388</td>\n",
       "      <td>0.015010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77000</td>\n",
       "      <td>APP_0000003001/M</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.284769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23000</td>\n",
       "      <td>APP_0000003002/M</td>\n",
       "      <td>1.1568</td>\n",
       "      <td>0.138219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>APP_0000003003/M</td>\n",
       "      <td>1.4580</td>\n",
       "      <td>0.200661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000</td>\n",
       "      <td>APP_0000003004/M</td>\n",
       "      <td>0.4134</td>\n",
       "      <td>0.098171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>28000</td>\n",
       "      <td>APP_0000003095/M</td>\n",
       "      <td>1.1364</td>\n",
       "      <td>0.473482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>43000</td>\n",
       "      <td>APP_0000003096/M</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.138079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99000</td>\n",
       "      <td>APP_0000003097/M</td>\n",
       "      <td>1.0983</td>\n",
       "      <td>0.299509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>28000</td>\n",
       "      <td>APP_0000003098/M</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>0.159553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>38000</td>\n",
       "      <td>APP_0000003099/M</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.018158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount    application.id      ab        cd\n",
       "0     1000  APP_0000003000/M  1.0388  0.015010\n",
       "1    77000  APP_0000003001/M  0.6163  0.284769\n",
       "2    23000  APP_0000003002/M  1.1568  0.138219\n",
       "3    90000  APP_0000003003/M  1.4580  0.200661\n",
       "4    15000  APP_0000003004/M  0.4134  0.098171\n",
       "..     ...               ...     ...       ...\n",
       "95   28000  APP_0000003095/M  1.1364  0.473482\n",
       "96   43000  APP_0000003096/M  0.6847  0.138079\n",
       "97   99000  APP_0000003097/M  1.0983  0.299509\n",
       "98   28000  APP_0000003098/M  0.3022  0.159553\n",
       "99   38000  APP_0000003099/M  0.4548  0.018158\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_results = legacy_preprocessing(applications.limit(100).toPandas())\n",
    "small_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now know the schems:\n",
    "# schema must have `` around field names with special characters\n",
    "RESULT_SCHEMA = \"`application.id` string, amount int, ab float, cd float\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark API akwardness\n",
    "\n",
    "mapInPandas accepts a function that get several pd.Dataframes (an iterator) \n",
    "and returns several pd.Dataframe\n",
    "\n",
    "So I need to wrap the legacy function in a for-loop generator\n",
    "\n",
    "## other weird bugs\n",
    "There are some bugs with fields that have '.' in them - even if surrounded by `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot resolve column name \"application.id\" among (amount, application.id, feature_a, feature_b, feature_c, feature_d, feature_e); did you mean to quote the `application.id` column?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m legacy_preprocessing(pd_df)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# schema must have `` around field names with special characters\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapInPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlegacy_preprocessing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m`application.id` string, amount int, ab float, cd float\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/pandas/map_ops.py:81\u001b[0m, in \u001b[0;36mPandasMapOpsMixin.mapInPandas\u001b[0;34m(self, func, schema)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, DataFrame)\n\u001b[1;32m     79\u001b[0m udf \u001b[38;5;241m=\u001b[39m pandas_udf(\n\u001b[1;32m     80\u001b[0m     func, returnType\u001b[38;5;241m=\u001b[39mschema, functionType\u001b[38;5;241m=\u001b[39mPythonEvalType\u001b[38;5;241m.\u001b[39mSQL_MAP_PANDAS_ITER_UDF)\n\u001b[0;32m---> 81\u001b[0m udf_column \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     82\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mmapInPandas(udf_column\u001b[38;5;241m.\u001b[39m_jc\u001b[38;5;241m.\u001b[39mexpr())\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/pandas/map_ops.py:81\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, DataFrame)\n\u001b[1;32m     79\u001b[0m udf \u001b[38;5;241m=\u001b[39m pandas_udf(\n\u001b[1;32m     80\u001b[0m     func, returnType\u001b[38;5;241m=\u001b[39mschema, functionType\u001b[38;5;241m=\u001b[39mPythonEvalType\u001b[38;5;241m.\u001b[39mSQL_MAP_PANDAS_ITER_UDF)\n\u001b[0;32m---> 81\u001b[0m udf_column \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     82\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mmapInPandas(udf_column\u001b[38;5;241m.\u001b[39m_jc\u001b[38;5;241m.\u001b[39mexpr())\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1636\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the column as a :class:`Column`.\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \n\u001b[1;32m   1622\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m[Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1636\u001b[0m     jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Column):\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"application.id\" among (amount, application.id, feature_a, feature_b, feature_c, feature_d, feature_e); did you mean to quote the `application.id` column?"
     ]
    }
   ],
   "source": [
    "def legacy_wrapper(pd_df_iter):\n",
    "    # mapInPandas accepts a function that get several pd.Dataframes (an iterator) and returns several pd.Dataframe\n",
    "    for pd_df in pd_df_iter:\n",
    "        yield legacy_preprocessing(pd_df)\n",
    "results = applications.mapInPandas(legacy_preprocessing, RESULT_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's skip the bugs \n",
    "Fix the data so there is no special character in column names\n",
    "## fix the legacy function\n",
    "This is the worse - I need to get into a function I don't know and try to fix its name handling\n",
    "\n",
    "## And... we made it\n",
    "We manged to scale the code.\n",
    "\n",
    "For one function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+------+----------+\n",
      "|  application_id|amount|    ab|        cd|\n",
      "+----------------+------+------+----------+\n",
      "|APP_0000003000/M|  1000|1.0388|0.01500996|\n",
      "|APP_0000003001/M| 77000|0.6163|  0.284769|\n",
      "|APP_0000003002/M| 23000|1.1568|0.13821888|\n",
      "|APP_0000003003/M| 90000| 1.458|0.20066129|\n",
      "|APP_0000003004/M| 15000|0.4134| 0.0981715|\n",
      "|APP_0000003005/M| 96000|1.5666|0.18056966|\n",
      "|APP_0000003006/M| 79000|1.1833|0.46287745|\n",
      "|APP_0000003007/M| 76000|0.2162|0.10360782|\n",
      "|APP_0000003008/M| 39000|1.7548|0.03062139|\n",
      "|APP_0000003009/M| 17000|1.4765| 0.3521403|\n",
      "|APP_0000003010/M| 96000|0.7312|0.49603468|\n",
      "|APP_0000003011/M| 70000|1.5012|0.27953613|\n",
      "|APP_0000003012/M| 56000|0.8664|0.04679532|\n",
      "|APP_0000003013/M|  5000|0.7576|0.05587302|\n",
      "|APP_0000003014/M| 74000|1.3384|0.08994418|\n",
      "|APP_0000003015/M|  1000|0.6803|0.67947406|\n",
      "|APP_0000003016/M| 19000|0.3561|0.04130205|\n",
      "|APP_0000003017/M| 37000|1.0392|0.18053356|\n",
      "|APP_0000003018/M| 86000|0.3175|0.08405565|\n",
      "|APP_0000003019/M| 16000|0.5896|0.05758036|\n",
      "+----------------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "applications_FIXED = applications.withColumnRenamed('application.id', 'application_id')  ### Fix the data\n",
    "\n",
    "def legacy_preprocessing_FIXED(pd_df):\n",
    "    pd_df['application_id'] = pd_df['application_id'] + \"/M\"  ### had to fix this line\n",
    "    pd_df['ab'] = pd_df.feature_a + pd_df.feature_b\n",
    "    pd_df['cd'] = pd_df.feature_c * pd_df.feature_d\n",
    "    # remove the 'features_X' columns\n",
    "    return pd_df.drop(columns=[col for col in pd_df.columns if col.startswith(\"feature\")])\n",
    "\n",
    "\n",
    "RESULT_SCHEMA_FIXED = \"application_id string, amount int, ab float, cd float\"\n",
    "\n",
    "def legacy_wrapper_FIXED(pd_df_iter):\n",
    "    for pd_df in pd_df_iter:\n",
    "        yield legacy_preprocessing_FIXED(pd_df)\n",
    "\n",
    "results = applications_FIXED.mapInPandas(legacy_wrapper_FIXED, RESULT_SCHEMA_FIXED)\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Creating test data)\n",
    "(Run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MONTHS = 36\n",
    "N_APPLICAIONS = 10_000\n",
    "applications1 = spark.range(N_APPLICAIONS, numPartitions=10).selectExpr(\n",
    "    \"printf('APP_%010d', INT(id)) AS `application.id`\",\n",
    "    \"INT(rand() * 100) * 1000 as amount\",\n",
    "    *[f\"round(rand(), 4) AS feature_{x}\" for x in \"abcde\"])\n",
    "applications1.write.mode(\"overwrite\").format(\"json\").save(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2880\n",
      "-rw-r--r--  1 tal.franji  wheel       0 Jun 16 18:38 _SUCCESS\n",
      "-rw-r--r--  1 tal.franji  wheel  145298 Jun 16 18:38 part-00000-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145358 Jun 16 18:38 part-00001-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145320 Jun 16 18:38 part-00002-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145360 Jun 16 18:38 part-00003-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145327 Jun 16 18:38 part-00004-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145293 Jun 16 18:38 part-00005-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145350 Jun 16 18:38 part-00006-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145250 Jun 16 18:38 part-00007-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145272 Jun 16 18:38 part-00008-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  145312 Jun 16 18:38 part-00009-44099317-5c47-4c15-9ea2-2180ec88a00d-c000.json\n",
      "{\"application.id\":\"APP_0000005000\",\"amount\":7000,\"feature_a\":0.3516,\"feature_b\":0.0801,\"feature_c\":0.617,\"feature_d\":0.7555,\"feature_e\":0.9899}\n",
      "{\"application.id\":\"APP_0000005001\",\"amount\":67000,\"feature_a\":0.6482,\"feature_b\":0.307,\"feature_c\":0.8612,\"feature_d\":0.4249,\"feature_e\":0.5872}\n",
      "{\"application.id\":\"APP_0000005002\",\"amount\":6000,\"feature_a\":0.952,\"feature_b\":0.5711,\"feature_c\":0.4173,\"feature_d\":0.4012,\"feature_e\":0.433}\n",
      "{\"application.id\":\"APP_0000005003\",\"amount\":18000,\"feature_a\":0.4694,\"feature_b\":0.0099,\"feature_c\":0.1076,\"feature_d\":0.3073,\"feature_e\":0.7621}\n",
      "{\"application.id\":\"APP_0000005004\",\"amount\":33000,\"feature_a\":0.2025,\"feature_b\":0.2157,\"feature_c\":0.1396,\"feature_d\":0.63,\"feature_e\":0.8393}\n",
      "{\"application.id\":\"APP_0000005005\",\"amount\":67000,\"feature_a\":0.2312,\"feature_b\":0.9883,\"feature_c\":0.0872,\"feature_d\":0.0372,\"feature_e\":0.2962}\n",
      "{\"application.id\":\"APP_0000005006\",\"amount\":46000,\"feature_a\":0.2039,\"feature_b\":0.9824,\"feature_c\":0.1044,\"feature_d\":0.2322,\"feature_e\":0.0404}\n",
      "{\"application.id\":\"APP_0000005007\",\"amount\":77000,\"feature_a\":0.8053,\"feature_b\":0.7959,\"feature_c\":0.4555,\"feature_d\":0.0343,\"feature_e\":0.451}\n",
      "{\"application.id\":\"APP_0000005008\",\"amount\":72000,\"feature_a\":0.8352,\"feature_b\":0.7068,\"feature_c\":0.8521,\"feature_d\":0.0842,\"feature_e\":0.3868}\n",
      "{\"application.id\":\"APP_0000005009\",\"amount\":93000,\"feature_a\":0.2522,\"feature_b\":0.0885,\"feature_c\":0.9944,\"feature_d\":0.1609,\"feature_e\":0.9072}\n"
     ]
    }
   ],
   "source": [
    "!ls -l {DATA_PATH}\n",
    "!head {DATA_PATH}{os.listdir(DATA_PATH)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
